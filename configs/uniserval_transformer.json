{
    "max_length": 100,
    "char_limit": 10,
    "scope":"UniversalTransformer",
    "num_classes":2,

    "with_char": false,
    "char_emb_dim": 20,
    "char_lstm_dim": 40,

    "batch_size": 100,
    "max_epochs": 100,
    "dropout_rate": 0.2,
    "learning_rate": 0.001,
    "optimizer": "adam",
    "lambda_l2": 0.0,
    "grad_clipper": 10.0,

    "context_layer_num": 1,
    "context_lstm_dim": 256,

    "slstm_layer_num": 5,

    "rnn":"slstm",
    "random_initialize":false,
    "step":5,
    "slstm_hidden_size":300,

    "highway_layer_num": 1,
    "with_highway": true,
    "with_match_highway": true,
    "with_aggregation_highway": true,

    "use_cudnn": false,

    "with_moving_average": 0.999,

    "weight_decay":1e-5,
    "context_fusion_method":"multi_head_git",
    "block_len":5,

    "loss":"focal_loss_binary_v2",

    "alpha":0.5,
    "gamma":2.0,
    "name":"focal_loss_binary_v2",

    "scale":30,
    "margin":0.35,

    "max_length":200,
    "attention_variables_3d":false,
    "use_target_space_embedding":false,
    "pos":"timing",
    "layer_postprocess_sequence":"da",
    "layer_preprocess_sequence":"n",
    "proximity_bias":false,
    "ffn_layer":"dense_relu_dense",
    "use_pad_remover":false,
    "hidden_size":256,
    "num_heads":8,
    "attention_dropout":0.2,
    "self_attention_type":"dot_product",
    "max_relative_position":5,
    "filter_size":512,
    "transformer_ffn_type":"sepconv",
    "activation_dtype":"bfloat32",
    "layer_prepostprocess_dropout":0.2,
    "num_encoder_layers":3,
    "norm_type":"layer",
    "norm_epsilon":1e-6,
    "attention_key_channels":0,
    "attention_value_channels":0,
    "relu_dropout":0.2,
    "mix_with_transformer":"before_ut",
    "recurrence_type":"act",
    "num_mixedin_layers":2,
    "num_rec_steps":3,
    "add_position_timing_signal":true,
    "add_step_timing_signal":true,
    "step_timing_signal_type":"learned",
    "add_or_concat_timing_signal":"add",
    "add_sru":false,
    "transform_bias_init":-1,
    "couple_carry_transform_gates":true,
    "lstm_forget_bias":1.0,
    "inputs_states_combination":"mh_attention_ffn_add",
    "gru_transformation":["state_transformation"],
    "lstm_transformation":["state_transformation"],
    "act_type":"basic",
    "act_max_steps":6,
    "act_halting_bias_init":1.0,
    "act_epsilon":0.01,
    "act_loss_weight":0.01,
    "gate_ffn_layer":"dense",
    "dwa_elements":true,
    "depth_embedding":true,
    "position_start_index":"step"
}
